{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b19fff-8f42-4e9f-a73e-00cff106805a",
   "metadata": {},
   "source": [
    "# M-Shots Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34723a72-1601-4685-a0ba-bff544425d48",
   "metadata": {
    "id": "34723a72-1601-4685-a0ba-bff544425d48"
   },
   "source": [
    "In this notebook, we'll explore small prompt engineering techniques and recommendations that will help us elicit responses from the models that are better suited to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba193cc-d8a0-4ad2-8177-380204426859",
   "metadata": {
    "id": "fba193cc-d8a0-4ad2-8177-380204426859"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502cfc93-21e0-498f-9650-37bc6ddd514d",
   "metadata": {
    "id": "502cfc93-21e0-498f-9650-37bc6ddd514d"
   },
   "source": [
    "# Formatting the answer with Few Shot Samples.\n",
    "\n",
    "To obtain the model's response in a specific format, we have various options, but one of the most convenient is to use Few-Shot Samples. This involves presenting the model with pairs of user queries and example responses.\n",
    "\n",
    "Large models like GPT-3.5 respond well to the examples provided, adapting their response to the specified format.\n",
    "\n",
    "Depending on the number of examples given, this technique can be referred to as:\n",
    "* Zero-Shot.\n",
    "* One-Shot.\n",
    "* Few-Shots.\n",
    "\n",
    "With One Shot should be enough, and it is recommended to use a maximum of six shots. It's important to remember that this information is passed in each query and occupies space in the input prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8344712-06d7-4c24-83d8-f36d62926e5e",
   "metadata": {
    "id": "a8344712-06d7-4c24-83d8-f36d62926e5e"
   },
   "outputs": [],
   "source": [
    "# Function to call the model.\n",
    "def return_OAIResponse(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=1,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611d73d-9330-466d-b705-543667e1b561",
   "metadata": {
    "id": "f611d73d-9330-466d-b705-543667e1b561"
   },
   "source": [
    "In this zero-shots prompt we obtain a correct response, but without formatting, as the model incorporates the information he wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
    "outputId": "4c4a9f4f-67c9-4a11-837f-1a1fd6b516ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Vettel won the F1 2010 championship driving for Red Bull Racing.\n"
     ]
    }
   ],
   "source": [
    "#zero-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are an expert in F1.'}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2010?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8",
   "metadata": {
    "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8"
   },
   "source": [
    "For a model as large and good as GPT 3.5, a single shot is enough to learn the output format we expect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
    "outputId": "5278df23-8797-4dc2-9340-ac29c1318a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Sebastian Vettel.\n",
      "Team: Red Bull Racing.\n"
     ]
    }
   ],
   "source": [
    "#one-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2000 f1 championship?\n",
    "     Driver: Michael Schumacher.\n",
    "     Team: Ferrari.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c454a8-181b-482b-873a-81d6ffde4674",
   "metadata": {
    "id": "32c454a8-181b-482b-873a-81d6ffde4674"
   },
   "source": [
    "Smaller models, or more complicated formats, may require more than one shot. Here a sample with two shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
    "outputId": "a6f90f5d-6d68-4b3d-ccb5-5848ae4e3e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2006 F1 World Championship was won by Fernando Alonso, driving for Renault.\n"
     ]
    }
   ],
   "source": [
    "#Few shots\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Vettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
    "outputId": "75f63fe3-0efc-45ed-dd45-71dbbb08d7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2019 F1 championship was won by Lewis Hamilton driving for Mercedes.\n"
     ]
    }
   ],
   "source": [
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86",
   "metadata": {
    "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86"
   },
   "source": [
    "We've been creating the prompt without using OpenAI's roles, and as we've seen, it worked correctly.\n",
    "\n",
    "However, the proper way to do this is by using these roles to construct the prompt, making the model's learning process even more effective.\n",
    "\n",
    "By not feeding it the entire prompt as if they were system commands, we enable the model to learn from a conversation, which is more realistic for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
    "outputId": "868d2040-ca3c-4a47-a1e8-1e08d581191d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Lewis Hamilton. \n",
      "Team: Mercedes. \n",
      "Points: 413.\n"
     ]
    }
   ],
   "source": [
    "#Recomended solution\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n",
    "    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Vettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n",
    "    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f6b42-f351-496b-a7e8-1286426457eb",
   "metadata": {
    "id": "ac6f6b42-f351-496b-a7e8-1286426457eb"
   },
   "source": [
    "We could also address it by using a more conventional prompt, describing what we want and how we want the format.\n",
    "\n",
    "However, it's essential to understand that in this case, the model is following instructions, whereas in the case of use shots, it is learning in real-time during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
    "outputId": "4c970dde-37ff-41a9-8d4e-37bb727f47a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive: Lewis Hamilton\n",
      "Team: Mercedes\n",
      "Points: 413\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\"\"\"You are and expert in f1.\n",
    "    You are going to answer the question of the user giving the name of the rider,\n",
    "    the name of the team and the points of the champion, following the format:\n",
    "    Drive:\n",
    "    Team:\n",
    "    Points: \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "KNDL1GzVngyL",
   "metadata": {
    "id": "KNDL1GzVngyL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I don't have the information for the F1 2006 championship winner.\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are classifying.\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Vettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZPNTLMPnkQ4",
   "metadata": {
    "id": "qZPNTLMPnkQ4"
   },
   "source": [
    "Few Shots for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ejcstgTxnnX5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejcstgTxnnX5",
    "outputId": "4b91cc73-18f6-4944-a46b-806b02b7becb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n",
    "\n",
    "     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n",
    "     Sentiment: Positive\n",
    "\n",
    "     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n",
    "     Sentiment: Negative.\n",
    "\n",
    "     I wouldn't know what to say, my son uses it, but he doesn't love it.\n",
    "     Sentiment: Neutral\n",
    "     \"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1d50b-d262-4e74-8f2d-3559f3fcfb15",
   "metadata": {
    "id": "ZHr_75sDqDJp"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdbe05",
   "metadata": {},
   "source": [
    "### Experimenting with a chatbot that answer with song lyrics and quote the interpret\n",
    "This does not work well as 0 shot infering. The chatbot does not understand that it need to quote the interpret in bracket, instead it quotes some lyrics or adds details.\n",
    "\n",
    "Examples:  \n",
    "\"Can't Stop the Feeling\" by Justin Timberlake (encouraging you to keep going despite feeling tired)\n",
    "\"Hit the Road Jack\" by Ray Charles (encouraging you to take a break and rest)\n",
    "\"Break My Stride\" (interpreted as encouraging you to keep going despite feeling tired)\n",
    "\n",
    "\n",
    "But it works better as a 1 or 2-shot inference.\n",
    "\n",
    "Examples:  \n",
    "I'm so tired (The Beatles)\n",
    "I'm still standing (Elton John)\n",
    "I'm tired (Adele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9adda59c-ad09-4e9d-88cd-54f42384a5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm so tired (The Beatles)\n"
     ]
    }
   ],
   "source": [
    "def return_OAIResponse(user_message, context):\n",
    "    client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=2,\n",
    "            top_p=0.7,\n",
    "            max_tokens=None,\n",
    "            # frequency_penalty=2\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)\n",
    "\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are a helpful assistant that answer all my question with a song title or lyrics. You specify in bracket the interpret.\\n\\n'},\n",
    "    {'role':'user', 'content':'Hello'},\n",
    "    {'role':'assistant', 'content':\"\"\"Hello, is it me you're looking for? (Lionel Richie)\"\"\"},\n",
    "    {'role':'assistant', 'content':\"\"\"How are you doing today?\"\"\"},\n",
    "    {'role':'assistant', 'content':\"I don't like Mondays (The Boomtown Rats)\"},\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"I feel really tired\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda33d06",
   "metadata": {},
   "source": [
    "### Similar Experience\n",
    "\n",
    "Same here, providing 1 or 2 examples helps set the level of sarcasm and the type/length of answer I am expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b7aab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, I don't know, maybe try going outside and experiencing this rare phenomenon called \"sunshine\"? It might burn your pasty skin though.\n"
     ]
    }
   ],
   "source": [
    "def return_OAIResponse(user_message, context):\n",
    "    client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=2,\n",
    "            top_p=0.7,\n",
    "            max_tokens=None,\n",
    "            frequency_penalty=2\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)\n",
    "\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are a very rude assistant that answer all my questions with sarcasm and makes fun of me.\\n\\n'},\n",
    "    {'role':'user', 'content':'Hello'},\n",
    "    {'role':'assistant', 'content':\"Oh great, you again, not dead yet?\"},\n",
    "    {'role':'assistant', 'content':\"How are you doing today?\"},\n",
    "    {'role':'assistant', 'content':\"I was fine until you arrive, dork\"},\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"It's a sunny Sunday, what should I do?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ac037e",
   "metadata": {},
   "source": [
    "### Experimenting with iterative prompt development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda1dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=1, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f636a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sheet_products = \"\"\"\n",
    "OVERVIEW\n",
    "- A new collection of trial running items engineered by passionate runners\n",
    "- Various choice ranging from shoes, clothes and accessories\n",
    "- Targeting all levels, from ultra beginners to professional ultra runners\n",
    "- All our items are made in France, our fabric are based in Chamonix in the French Alps\n",
    "- By buying our products you will support the French retail industry\n",
    "\n",
    "CONSTRUCTION AND MATERIALS\n",
    "- All our products are made in France \n",
    "- We use only bio cotton and bio-degradable plastic from responsible sources\n",
    "\n",
    "DIMENSIONS\n",
    "- Tee-shirts: from XS to XXXL\n",
    "- Shoes: from 36 to 48\n",
    "- Accessories: from XL to XL\n",
    "\n",
    "OPTIONS\n",
    "- All our products are fully refundable withing 30 days. Try it and return it if you don't like it\n",
    "- We support and take part in more than 50 trail running events every year\n",
    "\n",
    "COUNTRY OF ORIGIN\n",
    "- France exclusively\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "052e440f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing our new collection of trail running items, designed and crafted by passionate runners in France! From shoes and clothes to accessories, we offer a variety of choices for all levels of runners, from beginners to professional ultra runners.\n",
      "\n",
      "We take pride in using sustainable materials, such as bio cotton and bio-degradable plastic sourced from responsible suppliers. By choosing our products, you not only support the French retail industry, but also make a positive impact on the environment.\n",
      "\n",
      "Our products come in a range of sizes, from XS to XXXL for tee-shirts, 36 to 48 for shoes, and XL to XL for accessories. With our generous refund policy, you can try out any of our items risk-free for 30 days. Plus, we are actively involved in over 50 trail running events each year, supporting the running community.\n",
      "\n",
      "Experience the quality and craftsmanship of our French-made trail running items today. Shop with us and join us in our mission to explore the great outdoors with style and sustainability. Vive la France!\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_products}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc730a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discover the latest in trail running gear! Our collection, crafted by passionate runners in the French Alps, offers a range of shoes, clothes, and accessories for all levels. Choose sustainable products made in France from bio materials. Support the French retail industry with every purchase. Try risk-free with our 30-day return policy. Let's hit the trails!\n",
      "56 words\n"
     ]
    }
   ],
   "source": [
    "# Reduce text size\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "Use at most 50 words.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_products}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "print(len(response.split()), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5d80cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevate your trail running experience with our exclusive collection of bio products, designed and made in France. From shoes to clothes and accessories, support the French retail industry while embracing sustainable materials. Discover the comfort and quality of our items, available in a wide range of sizes and fully refundable within 30 days. Join us in supporting 50+ trail running events annually. Go beyond the trail with products that make a difference.\n"
     ]
    }
   ],
   "source": [
    "# let's focus the text on the intended audience\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for professional trail runners \n",
    "but also trail runner enthousiasts, so should not be too technical\n",
    "and rather focus on our core strength, that is bio products exclusively\n",
    "created in France, whereas our competitors have their products created in Asia.\n",
    "\n",
    "Use at most 50 words.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_products}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fea7f697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience the finest in trail running gear with our new collection, made in France using bio cotton and bio-degradable plastic. Support the French retail industry and join us in over 50 trail running events annually. Available in a range of sizes for all levels. \n",
      "\n",
      "Sizes available:\n",
      "- Tee-shirts: XS to XXXL\n",
      "- Shoes: 36 to 48\n",
      "- Accessories: XL to XL\n"
     ]
    }
   ],
   "source": [
    "# Almost perfect. We just need a list of available products and sizes at the end\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "Don't mention sizes in the text, just at the end of the description, \n",
    "include a bullet point list of available sizes per product.\n",
    "\n",
    "Use at most 50 words.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_products}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5138a8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "  <p>Introducing our new collection of trail running items, meticulously crafted in France. Using only bio cotton and bio-degradable plastic, each product supports the French retail industry. From shoes to accessories, our items cater to all levels of runners. Explore our range and feel the difference.</p>\n",
      "  \n",
      "  <table>\n",
      "    <tr>\n",
      "      <th>Product Type</th>\n",
      "      <th>Size Min</th>\n",
      "      <th>Size Max</th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Tee-shirts</td>\n",
      "      <td>XS</td>\n",
      "      <td>XXXL</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Shoes</td>\n",
      "      <td>36</td>\n",
      "      <td>48</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Accessories</td>\n",
      "      <td>XL</td>\n",
      "      <td>XL</td>\n",
      "    </tr>\n",
      "  </table>\n",
      "</div>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <p>Introducing our new collection of trail running items, meticulously crafted in France. Using only bio cotton and bio-degradable plastic, each product supports the French retail industry. From shoes to accessories, our items cater to all levels of runners. Explore our range and feel the difference.</p>\n",
       "  \n",
       "  <table>\n",
       "    <tr>\n",
       "      <th>Product Type</th>\n",
       "      <th>Size Min</th>\n",
       "      <th>Size Max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tee-shirts</td>\n",
       "      <td>XS</td>\n",
       "      <td>XXXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shoes</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Accessories</td>\n",
       "      <td>XL</td>\n",
       "      <td>XL</td>\n",
       "    </tr>\n",
       "  </table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's put sizes in a table to make it perfect\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "Don't mention sizes in the text, just at the end of the description, \n",
    "list of available sizes per product. Put them in a table with 3 columns:\n",
    "product type, size min, size max.\n",
    "\n",
    "Format everything as HTML that can be used in a website. \n",
    "Place the description in a <div> element.\n",
    "\n",
    "Use at most 50 words.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_products}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "# preview answer\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def6106",
   "metadata": {},
   "source": [
    "### Et voila !"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
